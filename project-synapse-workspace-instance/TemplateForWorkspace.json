{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "project-synapse-workspace-instance"
		},
		"project-synapse-workspace-instance-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'project-synapse-workspace-instance-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:project-synapse-workspace-instance.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"projectDataLakeStorageAccount1_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'projectDataLakeStorageAccount1'"
		},
		"projectSqlDatabase1_password": {
			"type": "secureString",
			"metadata": "Secure string for 'password' of 'projectSqlDatabase1'"
		},
		"project-synapse-workspace-instance-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://projectsynapsedatalake.dfs.core.windows.net"
		},
		"projectDataLakeStorageAccount1_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://airbnbdatastorage.dfs.core.windows.net/"
		},
		"projectSqlDatabase1_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "project-sql-server.database.windows.net"
		},
		"projectSqlDatabase1_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "project-sql-database"
		},
		"projectSqlDatabase1_properties_typeProperties_userName": {
			"type": "string",
			"defaultValue": "sql-server-admin"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/FintechDataMigration')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "GetTableListFromSqlDatabase",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderQuery": "SELECT \n    TABLE_SCHEMA AS SchemaName,\n    TABLE_NAME AS TableName\nFROM \n    INFORMATION_SCHEMA.TABLES\nWHERE \n    TABLE_TYPE = 'BASE TABLE' and TABLE_SCHEMA = 'fintech'\nORDER BY \n    SchemaName, TableName;",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "Database_project_SqlDatabase1",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "CopyEachTableToBronzeLayer",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "GetTableListFromSqlDatabase",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('GetTableListFromSqlDatabase').output.value",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "CopyTableToBronzeLayer",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "AzureSqlSource",
											"sqlReaderQuery": {
												"value": "@{concat('SELECT * FROM ', item().schemaName, '.', item().tableName)}",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "Database_project_SqlDatabase1",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "BronzeLayer_projectDataLakeStorageAccount1",
											"type": "DatasetReference",
											"parameters": {
												"tableName": {
													"value": "@item().TableName",
													"type": "Expression"
												},
												"schemaName": {
													"value": "@item().SchemaName",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					},
					{
						"name": "BronzeToSilver_ETL",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "CopyEachTableToBronzeLayer",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "BronzeToSilver_ETL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool1",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": null,
								"spark.dynamicAllocation.maxExecutors": null
							},
							"driverSize": "Small",
							"numExecutors": null
						}
					},
					{
						"name": "SilverToGold_ETL",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "BronzeToSilver_ETL",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "SilverToGold_ETL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool1",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": null,
								"spark.dynamicAllocation.maxExecutors": null
							},
							"driverSize": "Small",
							"numExecutors": null
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Database_project_SqlDatabase1')]",
				"[concat(variables('workspaceId'), '/notebooks/BronzeToSilver_ETL')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool1')]",
				"[concat(variables('workspaceId'), '/notebooks/SilverToGold_ETL')]",
				"[concat(variables('workspaceId'), '/datasets/BronzeLayer_projectDataLakeStorageAccount1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/BronzeLayer_projectDataLakeStorageAccount1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "projectDataLakeStorageAccount1",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"tableName": {
						"type": "string"
					},
					"schemaName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@{concat(dataset().tableName, '.parquet')}",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@{concat('bronze/', dataset().schemaName, '/', dataset().tableName)}",
							"type": "Expression"
						},
						"fileSystem": "fintech"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/projectDataLakeStorageAccount1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Database_project_SqlDatabase1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "projectSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/projectSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/project-synapse-workspace-instance-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('project-synapse-workspace-instance-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/project-synapse-workspace-instance-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('project-synapse-workspace-instance-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectDataLakeStorageAccount1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('projectDataLakeStorageAccount1_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('projectDataLakeStorageAccount1_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectSqlDatabase1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"server": "[parameters('projectSqlDatabase1_properties_typeProperties_server')]",
					"database": "[parameters('projectSqlDatabase1_properties_typeProperties_database')]",
					"encrypt": "mandatory",
					"trustServerCertificate": true,
					"authenticationType": "SQL",
					"userName": "[parameters('projectSqlDatabase1_properties_typeProperties_userName')]",
					"password": {
						"type": "SecureString",
						"value": "[parameters('projectSqlDatabase1_password')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_ad_hoc')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "select * from airbnb.customer_dim;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_create_schema')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "create schema airbnb;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_create_sp1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE PROCEDURE airbnb.BookingAggregation\nAS\nBEGIN\n    TRUNCATE TABLE airbnb.BookingCustomerAggregation;\n\n    INSERT INTO airbnb.BookingCustomerAggregation\n    SELECT \n        c.country,\n        COUNT_BIG(*) AS total_bookings,\n        SUM(ISNULL(b.amount, 0)) AS total_amount,\n        MAX(b.booking_date) AS last_booking_date\n    FROM \n        airbnb.bookings_fact b\n    JOIN \n        airbnb.customer_dim c ON b.customer_id = c.customer_id\n    GROUP BY \n        c.country;\nEND;\n\nEXEC [airbnb].[BookingAggregation];\n\nSELECT * FROM airbnb.BookingCustomerAggregation;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_create_table1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE airbnb.customer_dim (\n    customer_id INT, \n    first_name NVARCHAR(100),\n    last_name NVARCHAR(100),\n    email NVARCHAR(255),\n    phone_number NVARCHAR(50),\n    address NVARCHAR(255),\n    city NVARCHAR(100),\n    state NVARCHAR(100),\n    country NVARCHAR(100),\n    zip_code NVARCHAR(20),\n    signup_date DATE,\n    last_login DATETIME,\n    total_bookings INT,\n    total_spent DECIMAL(10, 2),\n    preferred_language NVARCHAR(50),\n    referral_code NVARCHAR(50),\n    account_status NVARCHAR(50)\n);\n\nSELECT * FROM airbnb.customer_dim;\n\nSELECT TOP 10 * FROM airbnb.customer_dim ORDER BY customer_id;\n\nTRUNCATE TABLE airbnb.customer_dim;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_create_table2')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE airbnb.bookings_fact (\n    booking_id NVARCHAR(100),\n    property_id NVARCHAR(100),\n    customer_id INT,\n    owner_id NVARCHAR(100),\n    check_in_date DATE,\n    check_out_date DATE,\n    booking_date DATETIME,\n    amount FLOAT,\n    currency NVARCHAR(10),\n    city NVARCHAR(100),\n    country NVARCHAR(100),\n    full_address NVARCHAR(255),\n    stay_duration BIGINT,\n    booking_year INT,\n    booking_month INT,\n    timestamp DATETIME\n);\n\nSELECT * FROM airbnb.bookings_fact;\n\nSELECT * FROM airbnb.bookings_fact WHERE booking_id = 'c1fc48f6-b35a-4910-858d-98803900ad53';\n\nDBCC FREEPROCCACHE;\n\nTRUNCATE TABLE airbnb.bookings_fact;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_create_table3')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE airbnb.BookingCustomerAggregation\nWITH (DISTRIBUTION = ROUND_ROBIN)\nAS\nSELECT \n    c.country,\n    COUNT_BIG(*) AS total_bookings,\n    SUM(ISNULL(b.amount, 0)) AS total_amount,\n    MAX(b.booking_date) AS last_booking_date\nFROM \n    airbnb.bookings_fact b\nJOIN \n    airbnb.customer_dim c ON b.customer_id = c.customer_id\nGROUP BY \n    c.country;\n\nSELECT * FROM airbnb.BookingCustomerAggregation;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool_create_user')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE USER [project-data-factory-instance] FROM EXTERNAL PROVIDER;\nEXEC sp_addrolemember 'db_datareader', 'project-data-factory-instance';\nEXEC sp_addrolemember 'db_datawriter', 'project-data-factory-instance';\nEXEC sp_addrolemember 'db_owner', 'project-data-factory-instance';\n\nGRANT SELECT, INSERT, UPDATE, DELETE, CONTROL ON SCHEMA::airbnb TO [project-data-factory-instance];\n\nSELECT \n    dp.name AS PrincipalName,\n    dp.type_desc AS PrincipalType,\n    p.permission_name AS PermissionName,\n    p.state_desc AS PermissionState\nFROM \n    sys.database_permissions p\nJOIN \n    sys.database_principals dp ON p.grantee_principal_id = dp.principal_id\nWHERE dp.name = 'project-data-factory-instance';",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "projectsqlpool",
						"poolName": "projectsqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/BronzeToSilver_ETL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b89f0835-a5ae-4226-a7a4-e53623080f5a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql.functions import *\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Define paths\r\n",
							"base_path = \"abfss://fintech@airbnbdatagds.dfs.core.windows.net/bronze/fintech/\"\r\n",
							"output_base_path = \"abfss://fintech@airbnbdatagds.dfs.core.windows.net/silver/fintech/\"\r\n",
							"\r\n",
							"spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"'''\r\n",
							"Transformation for Accounts dataset - \r\n",
							"    A new column, \"AccountAgeYears\", is added, which calculates how long each account has been active \r\n",
							"    by determining the difference between the current date and the account's open date, then converting it to years.\r\n",
							"'''\r\n",
							"def transform_accounts():\r\n",
							"    df = spark.read.parquet(f\"{base_path}Accounts/Accounts.parquet\")\r\n",
							"    # Transformation: Calculate account age in years\r\n",
							"    df_transformed = df.withColumn(\"AccountAgeYears\", \r\n",
							"                                   round(datediff(current_date(), col(\"OpenDate\")) / 365.25, 2))\r\n",
							"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Accounts/\")\r\n",
							"    "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"'''\r\n",
							"Transformation for Customers dataset - \r\n",
							"    A new FullName column is created by concatenating FirstName and LastName.\r\n",
							"    A MaskedEmail column is created, where the email address is partially hidden \r\n",
							"    (the part before the @ symbol is replaced by ***).\r\n",
							"'''\r\n",
							"def transform_customers():\r\n",
							"    df = spark.read.parquet(f\"{base_path}Customers/Customers.parquet\")\r\n",
							"    # Transformation: Create a full name column and mask the email address\r\n",
							"    df_transformed = df.withColumn(\"FullName\", concat_ws(\" \", col(\"FirstName\"), col(\"LastName\"))) \\\r\n",
							"                       .withColumn(\"MaskedEmail\", \r\n",
							"                                   concat(lit(\"***@\"), substring_index(col(\"Email\"), \"@\", -1)))\r\n",
							"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Customers/\")\r\n",
							"    "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"'''\r\n",
							"Transformation for Loans dataset - \r\n",
							"    TotalInterest: The total interest paid on the loan.\r\n",
							"    LoanDurationYears: The duration of the loan in years.\r\n",
							"\r\n",
							"Total Interest Calculation:\r\n",
							"    The code calculates the total interest on the loan using the formula:\r\n",
							"            TotalInterest = (LoanAmount X InterestRate)/100 \r\n",
							"    The result is explicitly cast to decimal(28,8) to ensure precise storage in the Delta table.\r\n",
							"\r\n",
							"Loan Duration Calculation:\r\n",
							"    The duration of the loan in years is calculated based on the difference between the LoanEndDate and LoanStartDate.\r\n",
							"    The result is rounded to 2 decimal places for clarity.\r\n",
							"'''\r\n",
							"def transform_loans():\r\n",
							"    df = spark.read.parquet(f\"{base_path}Loans/Loans.parquet\")\r\n",
							"    # Transformation: Calculate total interest with explicit casting to match the Delta table\r\n",
							"    df_transformed = df.withColumn(\"TotalInterest\", \r\n",
							"                                   (col(\"LoanAmount\") * col(\"InterestRate\") / 100).cast(\"decimal(28,8)\")) \\\r\n",
							"                       .withColumn(\"LoanDurationYears\", \r\n",
							"                                   round(datediff(col(\"LoanEndDate\"), col(\"LoanStartDate\")) / 365.25, 2))\r\n",
							"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Loans/\")\r\n",
							"    "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"'''\r\n",
							"Transformation for Payments dataset - \r\n",
							"    Transform the dataset by adding a new column DaysSinceLastPayment, \r\n",
							"    which calculates how many days have passed since the last payment.\r\n",
							"'''\r\n",
							"def transform_payments():\r\n",
							"    df = spark.read.parquet(f\"{base_path}Payments/Payments.parquet\")\r\n",
							"    # Transformation: Calculate days since last payment\r\n",
							"    df_transformed = df.withColumn(\"DaysSinceLastPayment\", \r\n",
							"                                   datediff(current_date(), col(\"PaymentDate\")))\r\n",
							"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Payments/\")\r\n",
							"    "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"'''\r\n",
							"Transformation for Transactions dataset - \r\n",
							"    Transform the dataset by creating a new column TransactionCategory based on the value of the TransactionType column.\r\n",
							"    If the transaction is a Deposit, it's categorized as Income.\r\n",
							"    If it's a Withdrawal, it's categorized as Expense.\r\n",
							"    Any other transaction type falls into the Other category.\r\n",
							"'''\r\n",
							"def transform_transactions():\r\n",
							"    df = spark.read.parquet(f\"{base_path}Transactions/Transactions.parquet\")\r\n",
							"    # Transformation: Categorize transaction types\r\n",
							"    df_transformed = df.withColumn(\"TransactionCategory\", \r\n",
							"                                   when(col(\"TransactionType\") == \"Deposit\", \"Income\")\r\n",
							"                                   .when(col(\"TransactionType\") == \"Withdrawal\", \"Expense\")\r\n",
							"                                   .otherwise(\"Other\"))\r\n",
							"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Transactions/\")\r\n",
							"    "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"'''\r\n",
							"Process each table - \r\n",
							"    transform_accounts(): Processes the Accounts dataset, typically applying transformations \r\n",
							"    like calculating account age.\r\n",
							"\r\n",
							"    transform_customers(): Processes the Customers dataset, applying transformations such as \r\n",
							"    creating a full name and masking email addresses.\r\n",
							"\r\n",
							"    transform_loans(): Processes the Loans dataset, calculating fields like total interest and loan duration.\r\n",
							"\r\n",
							"    transform_payments(): Processes the Payments dataset, calculating how many days have passed\r\n",
							"    since the last payment.\r\n",
							"\r\n",
							"    transform_transactions(): Processes the Transactions dataset, categorizing transaction types \r\n",
							"    (e.g., Deposit -> Income, Withdrawal -> Expense).\r\n",
							"'''\r\n",
							"transform_accounts()\r\n",
							"transform_customers()\r\n",
							"transform_loans()\r\n",
							"transform_payments()\r\n",
							"transform_transactions()\r\n",
							"\r\n",
							"print(\"Bronze To Silver Completed !!\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SilverToGold_ETL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e465d9d6-5676-42fe-8bf9-ee61f7fe592a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql.functions import *\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Define paths\r\n",
							"silver_base_path = \"abfss://fintech@airbnbdatagds.dfs.core.windows.net/silver/fintech/\"\r\n",
							"output_base_path = \"abfss://fintech@airbnbdatagds.dfs.core.windows.net/gold/fintech/\"\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Load data from the silver layer\r\n",
							"accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\r\n",
							"customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\r\n",
							"loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\r\n",
							"payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\r\n",
							"transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dim_customers_df = customers_df.select(\n",
							"    col(\"CustomerID\").alias(\"customer_id\"),\n",
							"    col(\"FirstName\").alias(\"first_name\"),\n",
							"    col(\"LastName\").alias(\"last_name\"),\n",
							"    col(\"Email\").alias(\"email\"),\n",
							"    col(\"PhoneNumber\").alias(\"phone_number\"),\n",
							"    col(\"Address\").alias(\"address\"),\n",
							"    col(\"City\").alias(\"city\"),\n",
							"    col(\"State\").alias(\"state\"),\n",
							"    col(\"Country\").alias(\"country\"),\n",
							"    col(\"ZipCode\").alias(\"zip_code\"),\n",
							"    col(\"SignupDate\").alias(\"signup_date\")\n",
							")\n",
							"\n",
							"dim_customers_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_customers/\")\n",
							""
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dim_accounts_df = accounts_df.select(\n",
							"    col(\"AccountID\").alias(\"account_id\"),\n",
							"    col(\"AccountType\").alias(\"account_type\"),\n",
							"    col(\"Balance\").alias(\"balance\"),\n",
							"    col(\"OpenDate\").alias(\"open_date\"),\n",
							"    col(\"AccountAgeYears\").alias(\"account_age_years\")\n",
							")\n",
							"\n",
							"dim_accounts_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_accounts/\")\n",
							""
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dim_loans_df = loans_df.select(\n",
							"    col(\"LoanID\").alias(\"loan_id\"),\n",
							"    col(\"LoanType\").alias(\"loan_type\"),\n",
							"    col(\"LoanAmount\").alias(\"loan_amount\"),\n",
							"    col(\"InterestRate\").alias(\"interest_rate\"),\n",
							"    col(\"LoanStartDate\").alias(\"loan_start_date\"),\n",
							"    col(\"LoanEndDate\").alias(\"loan_end_date\"),\n",
							"    col(\"TotalInterest\").alias(\"total_interest\"),\n",
							"    col(\"LoanDurationYears\").alias(\"loan_duration_years\")\n",
							")\n",
							"\n",
							"dim_loans_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_loans/\")\n",
							""
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"fact_payments_df = payments_df \\\n",
							"    .join(loans_df.select(\"LoanID\", \"CustomerID\"), \"LoanID\") \\\n",
							"    .select(\n",
							"        col(\"PaymentID\").alias(\"payment_id\"),\n",
							"        col(\"LoanID\").alias(\"loan_id\"),\n",
							"        col(\"CustomerID\").alias(\"customer_id\"),\n",
							"        col(\"PaymentDate\").alias(\"payment_date\"),\n",
							"        col(\"PaymentAmount\").alias(\"payment_amount\"),\n",
							"        col(\"PaymentMethod\").alias(\"payment_method\")\n",
							"    )\n",
							"\n",
							"fact_payments_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_payments/\")\n",
							""
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"fact_transactions_df = transactions_df \\\n",
							"    .join(accounts_df.select(\"AccountID\", \"CustomerID\"), \"AccountID\") \\\n",
							"    .select(\n",
							"        col(\"TransactionID\").alias(\"transaction_id\"),\n",
							"        col(\"AccountID\").alias(\"account_id\"),\n",
							"        col(\"CustomerID\").alias(\"customer_id\"),\n",
							"        col(\"TransactionDate\").alias(\"transaction_date\"),\n",
							"        col(\"Amount\").alias(\"amount\"),\n",
							"        col(\"TransactionType\").alias(\"transaction_type\"),\n",
							"        col(\"Description\").alias(\"description\")\n",
							"    )\n",
							"\n",
							"fact_transactions_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_transactions/\")\n",
							""
						],
						"outputs": [],
						"execution_count": 12
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sparkpool1')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 5
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "centralindia"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/projectsqlpool')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "centralindia"
		}
	]
}