{
	"name": "BronzeToSilver_ETL",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "b89f0835-a5ae-4226-a7a4-e53623080f5a"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import *\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Define paths\r\n",
					"base_path = \"abfss://fintech@airbnbdatagds.dfs.core.windows.net/bronze/fintech/\"\r\n",
					"output_base_path = \"abfss://fintech@airbnbdatagds.dfs.core.windows.net/silver/fintech/\"\r\n",
					"\r\n",
					"spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"'''\r\n",
					"Transformation for Accounts dataset - \r\n",
					"    A new column, \"AccountAgeYears\", is added, which calculates how long each account has been active \r\n",
					"    by determining the difference between the current date and the account's open date, then converting it to years.\r\n",
					"'''\r\n",
					"def transform_accounts():\r\n",
					"    df = spark.read.parquet(f\"{base_path}Accounts/Accounts.parquet\")\r\n",
					"    # Transformation: Calculate account age in years\r\n",
					"    df_transformed = df.withColumn(\"AccountAgeYears\", \r\n",
					"                                   round(datediff(current_date(), col(\"OpenDate\")) / 365.25, 2))\r\n",
					"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Accounts/\")\r\n",
					"    "
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"'''\r\n",
					"Transformation for Customers dataset - \r\n",
					"    A new FullName column is created by concatenating FirstName and LastName.\r\n",
					"    A MaskedEmail column is created, where the email address is partially hidden \r\n",
					"    (the part before the @ symbol is replaced by ***).\r\n",
					"'''\r\n",
					"def transform_customers():\r\n",
					"    df = spark.read.parquet(f\"{base_path}Customers/Customers.parquet\")\r\n",
					"    # Transformation: Create a full name column and mask the email address\r\n",
					"    df_transformed = df.withColumn(\"FullName\", concat_ws(\" \", col(\"FirstName\"), col(\"LastName\"))) \\\r\n",
					"                       .withColumn(\"MaskedEmail\", \r\n",
					"                                   concat(lit(\"***@\"), substring_index(col(\"Email\"), \"@\", -1)))\r\n",
					"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Customers/\")\r\n",
					"    "
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"'''\r\n",
					"Transformation for Loans dataset - \r\n",
					"    TotalInterest: The total interest paid on the loan.\r\n",
					"    LoanDurationYears: The duration of the loan in years.\r\n",
					"\r\n",
					"Total Interest Calculation:\r\n",
					"    The code calculates the total interest on the loan using the formula:\r\n",
					"            TotalInterest = (LoanAmount X InterestRate)/100 \r\n",
					"    The result is explicitly cast to decimal(28,8) to ensure precise storage in the Delta table.\r\n",
					"\r\n",
					"Loan Duration Calculation:\r\n",
					"    The duration of the loan in years is calculated based on the difference between the LoanEndDate and LoanStartDate.\r\n",
					"    The result is rounded to 2 decimal places for clarity.\r\n",
					"'''\r\n",
					"def transform_loans():\r\n",
					"    df = spark.read.parquet(f\"{base_path}Loans/Loans.parquet\")\r\n",
					"    # Transformation: Calculate total interest with explicit casting to match the Delta table\r\n",
					"    df_transformed = df.withColumn(\"TotalInterest\", \r\n",
					"                                   (col(\"LoanAmount\") * col(\"InterestRate\") / 100).cast(\"decimal(28,8)\")) \\\r\n",
					"                       .withColumn(\"LoanDurationYears\", \r\n",
					"                                   round(datediff(col(\"LoanEndDate\"), col(\"LoanStartDate\")) / 365.25, 2))\r\n",
					"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Loans/\")\r\n",
					"    "
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"'''\r\n",
					"Transformation for Payments dataset - \r\n",
					"    Transform the dataset by adding a new column DaysSinceLastPayment, \r\n",
					"    which calculates how many days have passed since the last payment.\r\n",
					"'''\r\n",
					"def transform_payments():\r\n",
					"    df = spark.read.parquet(f\"{base_path}Payments/Payments.parquet\")\r\n",
					"    # Transformation: Calculate days since last payment\r\n",
					"    df_transformed = df.withColumn(\"DaysSinceLastPayment\", \r\n",
					"                                   datediff(current_date(), col(\"PaymentDate\")))\r\n",
					"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Payments/\")\r\n",
					"    "
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"'''\r\n",
					"Transformation for Transactions dataset - \r\n",
					"    Transform the dataset by creating a new column TransactionCategory based on the value of the TransactionType column.\r\n",
					"    If the transaction is a Deposit, it's categorized as Income.\r\n",
					"    If it's a Withdrawal, it's categorized as Expense.\r\n",
					"    Any other transaction type falls into the Other category.\r\n",
					"'''\r\n",
					"def transform_transactions():\r\n",
					"    df = spark.read.parquet(f\"{base_path}Transactions/Transactions.parquet\")\r\n",
					"    # Transformation: Categorize transaction types\r\n",
					"    df_transformed = df.withColumn(\"TransactionCategory\", \r\n",
					"                                   when(col(\"TransactionType\") == \"Deposit\", \"Income\")\r\n",
					"                                   .when(col(\"TransactionType\") == \"Withdrawal\", \"Expense\")\r\n",
					"                                   .otherwise(\"Other\"))\r\n",
					"    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Transactions/\")\r\n",
					"    "
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"'''\r\n",
					"Process each table - \r\n",
					"    transform_accounts(): Processes the Accounts dataset, typically applying transformations \r\n",
					"    like calculating account age.\r\n",
					"\r\n",
					"    transform_customers(): Processes the Customers dataset, applying transformations such as \r\n",
					"    creating a full name and masking email addresses.\r\n",
					"\r\n",
					"    transform_loans(): Processes the Loans dataset, calculating fields like total interest and loan duration.\r\n",
					"\r\n",
					"    transform_payments(): Processes the Payments dataset, calculating how many days have passed\r\n",
					"    since the last payment.\r\n",
					"\r\n",
					"    transform_transactions(): Processes the Transactions dataset, categorizing transaction types \r\n",
					"    (e.g., Deposit -> Income, Withdrawal -> Expense).\r\n",
					"'''\r\n",
					"transform_accounts()\r\n",
					"transform_customers()\r\n",
					"transform_loans()\r\n",
					"transform_payments()\r\n",
					"transform_transactions()\r\n",
					"\r\n",
					"print(\"Bronze To Silver Completed !!\")\r\n",
					""
				],
				"execution_count": null
			}
		]
	}
}